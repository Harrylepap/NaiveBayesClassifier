# Naive Bayes Classifier pour Machine Learning

[![N|Solid](http://www.eskimoz.fr/wp-content/uploads/2017/05/impact-du-Machine-Learning-sur-le-SEO.png)](https://www.facebook.com/rakotondratompobakoharry)

Naive Bayes Classifier est un algorithme populaire en Machine Learning. Câ€™est un algorithme du Supervised Learning utilisÃ© pour la classification. Il est particuliÃ¨rement utile pour les problÃ©matiques de classification de texte. Un exemple dâ€™utilisation du Naive Bayes est celui du filtre anti-spam. 
On mettra en place un Â« SPAM Filter Â» en utilisant le Naive Bayes Classifier. Notre classifieur se basera sur Python et sa librairie de Machine Learning : Â« Sickit Learn Â».

Lâ€™algorithme prendra en entrÃ©e un e-mail et nous indiquera sâ€™il sâ€™agit dâ€™un mail ou non.

Comme plan, nous avons

  - PrÃ©sentation des donnÃ©es
  - Chargement des donnÃ©es
  - PrÃ©paration du classifieur NaÃ¯ve Bayes
  - Entrainement du Naive Bayes Classifier
  - Tester le Spam Filter
  - Piste dâ€™amÃ©liorations
  - Conlusion

### PrÃ©sentation des donnÃ©es
Naive Bayes est un algorithme dâ€™apprentissage supervisÃ©. De ce fait, Il faudra quâ€™on lui fournisse une base de donnÃ©es dâ€™apprentissage supervisÃ©.

Notre jeu dâ€™apprentissage sera une collection de mails. Pour chacun dâ€™eux, on indiquera sâ€™il sâ€™agit dâ€™un SPAM ou non.

| DonnÃ©es dâ€™entrÃ©e | Label |
| ------ | ------ |
| 1er mail |Spam |
| 2eme mail | Non spam |
| 3eme mail | Non spam |
|... | ....|
Notre Training Set est composÃ© de :
  - 500 mails Spam
  - 2500 mails Non spam (Ham)



### Chargement des donnÃ©es
Tout dâ€™abord, on chargera nos mails en utilisant les modules Â« OS Â» et Â« IO Â» de Python. Voici le snippet de code de lecture et chargement des mails :

```python
def lectureContenuMailSansHeader(nom):
    contenueMail = False
    ligne = []
    descriptionFichier = io.open(nom, 'r', encoding='latin1')
    for line in descriptionFichier:
        if contenueMail:
            ligne.append(line)
        elif line == '\n':
            contenueMail = True
        message = '\n'.join(ligne)
    descriptionFichier.close()
    return message


def lectureMailDossier(chemin, classification):   
    os.chdir(chemin)
    fichiers = os.listdir(chemin)
    for fichier in fichiers:
        message = lectureContenuMailSansHeader(fichier)
        X.append(message)
        Y.append(classification)


#DATA
## dossier
dossierHam =  r'C:\Users\Harrylepap\PycharmProjects\anti-spam-machine-learning\emails\ham'
dossierSpam =  r'C:\Users\Harrylepap\PycharmProjects\anti-spam-machine-learning\emails\spam'

## type de mail
spam_type = "SPAM"
ham_type  = "HAM | Message normale"

## initialisation
i=0
##les tableaux X et Y seront de la meme taille et ordonnes
### represente l'input Data (ici les mails)
X = []
### indique s'il s'agit d'un mail ou non
### etiquettes (labels) pour la matrice
Y = []
```

A lâ€™exÃ©cution de ce code, on chargera 3000 mails (ce qui constitue notre Training Set).
> Pensez Ã  modifier le chemin vers le rÃ©pertoire contenant les mails lors de lâ€™exÃ©cution du script sur votre machine.

### PrÃ©paration du classifieur NaÃ¯ve Bayes
Je vais illustrÃ© comment opÃ¨re cet algorithme en classifiant des fruits en fonction de leurs caractÃ©ristiques. On calcul une probabilitÃ© conditionnelle pour savoir sâ€™il sâ€™agit dâ€™une banane, dâ€™une orange ou un autre fruit. La probabilitÃ© conditionnelle est calculÃ©e en se basant sur la cardinalitÃ©/proportion de chaque caractÃ©ristique du fruit dans notre jeu de donnÃ©es.
Pour la classification de mails en SPAM/Non Spam, câ€™est la mÃªme logique qui sâ€™applique. En effet, les mails SPAM contiennent gÃ©nÃ©ralement une proportion Ã©levÃ©e de mots comme Â« Gagner, Gratuit,â€¦etc Â» alors que dans un mail normal, ce ne sera pas le cas.
>Pour classifier nos emails avec NaÃ¯ve Bayes, on calcule le nombre dâ€™occurrence des mots dans chaque mail.

On doit, pour chaque mail, comptabiliser le nombre dâ€™occurrence des mots. Cela permettra de calculer la probabilitÃ© conditionnelle comme dans lâ€™exemple de classification des fruits.

Python nous simplifie la vie en nous proposant une fonction qui effectue ce calcul. Il sâ€™agit de la mÃ©thode fit_transform de la classe countVectorizer.

```python
vecteur = CountVectorizer()
counts = vecteur.fit_transform(matrice['X'].values)
```
La variable counts contiendra une matrix contenant, pour chaque document, le nombre dâ€™occurences de chaque mots

### Entrainement du Naive Bayes Classifier


Tous les ingrÃ©dients sont lÃ , il nous reste quâ€™a entraÃ®ner notre filtre anti-spam. Pour ce faire, on lui filera les mails 3000 mails quâ€™on a chargÃ© auparavant. Pour chaque mail que le classifieur lira, on lui indiquera sâ€™il sâ€™agit de SPAM ou non.

Sickit_learn nous propose la classe MultinomialNB (NB pour NaÃ¯ve Bayes), qui fera tous le travail pour nous.

```python
classifier = MultinomialNB()
targets = matrice['Y'].values
classifier.fit(counts, targets)
```
Note :

- Pour Ãªtre plus prÃ©cis, on donne Ã  MultinomialNB() la version Â« codifiÃ©e Â» des mails quâ€™on a calculÃ© avec CountVectorizer
- Pour chaque mail, on spÃ©cifie sâ€™il sâ€™agit de SPAM ou non (voir lâ€™appel classifier.fit(counts, targets))

Et voilÃ  ! 
### Tester le Spam Filter

Il nous reste plus quâ€™Ã  tester notre filtre anti-spam. Certes, il nâ€™est pas de la tremple que celui de Google, mais, regardons ce quâ€™il a dans le ventre.
-Vu que les mails de notre Training Set sont en anglais et quelques mail en Malagasy, on lui donnera un tableau de mail Ã  travailler
```python
TableauDePhrase = ['Free Viagra now!!!', "Bonjour Sandrine, comment ca va? je t'aime", "Ndao hilely fory be"]
compteurVecteur = vecteur.transform(TableauDePhrase)
predictions = classifier.predict(compteurVecteur)
```

La sortie de l'application donnera :
```batch
Free Viagra now!!!  =>  SPAM
Bonjour Sandrine, comment ca va? je t'aime  =>  HAM | Message normale
Ndao hilely fory be  =>  SPAM
```

### Piste dâ€™amÃ©liorations

Le Spam Filter quâ€™on vient dâ€™implÃ©menter est assez rudimentaire. En effet, par dÃ©faut, countVectorizer comptabilise les occurrences de chaque mots. Par ailleurs, les mots Â« Apple Â» et Â« Apples Â» peuvent Ãªtre considÃ©rÃ©s diffÃ©rents. La mÃªme histoire pour le respect de la casse (par exemple GRATUIT et gratuit).

Pour mieux optimiser lâ€™algorithme, on peut appliquer quelques techniques de Text Analysis. La documentation de Python en [explique le principe avec un des exemples illustratifs.](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform)

### Conclusion
Vous venez dâ€™implÃ©menter votre premier Spam Filter. Tentez dâ€™entraÃ®ner ce filtre sur vos mails FranÃ§ais et partagez vos retrouvailles en commentaire ğŸ˜‰